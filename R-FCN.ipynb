{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementación de R - Fully Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importa paquetes y bibliotecas\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import PIL\n",
    "import os\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Activation, Dense, BatchNormalization, Dropout,concatenate, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Input, Reshape\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.core import SpatialDropout2D\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings('ignore')\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "np.random.seed(101)\n",
    "\n",
    "import re\n",
    "numbers = re.compile(r'(\\d+)')\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar los datos\n",
    "trainx_rgb = sorted(glob.glob('./dataset/trainx/*.png'), key=numericalSort) #lee el conjunto de datos \"trainx\" contiene las imagenes rgb\n",
    "X_train = np.array([np.array(Image.open(fname)) for fname in trainx_rgb])\n",
    "\n",
    "trainy_mask = sorted(glob.glob('./dataset/trainyy/*.png'), key=numericalSort) # lee el conjunto de datos \"trainyy 2 contiene las imagenes binarias\n",
    "Y_train = np.array([np.array(Image.open(fname)) for fname in trainy_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion para reajustar las imágenes a 256x192\n",
    "def resize(filename, size = (256,192)):\n",
    "    im = Image.open(filename)\n",
    "    im_resized = im.resize(size, Image.ANTIALIAS)\n",
    "    return (im_resized)\n",
    "\n",
    "X_train_resized = []\n",
    "Y_train_resized = []\n",
    "\n",
    "for i in range(len(trainx_rgb)):\n",
    "    X_train_resized.append(resize(trainx_rgb[i]))\n",
    "    Y_train_resized.append(resize(trainy_mask[i]))\n",
    "    \n",
    "X_train = np.array([np.array(img) for img in X_train_resized])\n",
    "Y_train = np.array([np.array(img) for img in Y_train_resized])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size = 0.25, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tamaño de las imágenes de entrada\n",
    "plt.figure(figsize=(20,9))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(X_train[5])\n",
    "plt.xlabel(\"Tamaño: \"+str(np.array(X_train[1]).shape))\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(X_train[10])\n",
    "plt.xlabel(\"Tamaño: \"+str(np.array(X_train[10]).shape))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funciones para calcular las métricas de evaluación\n",
    "def jaccard_distance(y_true, y_pred, smooth=100):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.square(y_true), axis = -1) + K.sum(K.square(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return (1 - jac)\n",
    "def iou(y_true, y_pred, smooth = 100):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.square(y_true), axis = -1) + K.sum(K.square(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return jac\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth = 100):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "def precision(y_true, y_pred):\n",
    "    '''Calculates the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    '''\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "def recall(y_true, y_pred):\n",
    "    '''Calculates the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    '''\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "def accuracy(y_true, y_pred):\n",
    "    '''Calculates the mean accuracy rate across all predictions for binary\n",
    "    classification problems.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.round(y_pred)))\n",
    "\n",
    "#funcion para algunas técnicas de aummento de datos como rotación\n",
    "def random_rotation(x_image, y_image):\n",
    "    rows_x,cols_x, chl_x = x_image.shape\n",
    "    rows_y,cols_y = y_image.shape\n",
    "    rand_num = np.random.randint(-40,40)\n",
    "    M1 = cv2.getRotationMatrix2D((cols_x/2,rows_x/2),rand_num,1)\n",
    "    M2 = cv2.getRotationMatrix2D((cols_y/2,rows_y/2),rand_num,1)\n",
    "    x_image = cv2.warpAffine(x_image,M1,(cols_x,rows_x))\n",
    "    y_image = cv2.warpAffine(y_image.astype('float32'),M2,(cols_y,rows_y))\n",
    "    return x_image, y_image.astype('float32')\n",
    "\n",
    "#funcion para algunas técnicas de aummento de datos como volteo horizontal\n",
    "def horizontal_flip(x_image, y_image):\n",
    "    x_image = cv2.flip(x_image, 1)\n",
    "    y_image = cv2.flip(y_image.astype('float32'), 1)\n",
    "    return x_image, y_image.astype('float32')\n",
    "\n",
    "def vertical_flip(x_image, y_image):\n",
    "    x_image = cv2.flip(x_image, 0)\n",
    "    y_image = cv2.flip(y_image.astype('float32'), 0)\n",
    "    return x_image, y_image.astype('float32')\n",
    "\n",
    "#def both_flip(x_image, y_image):\n",
    "#    x_image = cv2.flip(x_image, -1)\n",
    "#    y_image = cv2.flip(y_image.astype('float32'), -1)\n",
    "#    return x_image, y_image.astype('float32')\n",
    "\n",
    "#funcion para algunas técnicas de aummento de datos como volteo horizontal\n",
    "def img_augmentation(x_train, y_train):\n",
    "    x_rotat = []\n",
    "    y_rotat = []\n",
    "    x_flip = []\n",
    "    y_flip = []\n",
    "    x_vert = []\n",
    "    y_vert = []\n",
    "    #x_both = []\n",
    "    #y_both = []\n",
    "    x_nois = []\n",
    "    for idx in range(len(x_train)):\n",
    "        x,y = random_rotation(x_train[idx], y_train[idx])\n",
    "        x_rotat.append(x)\n",
    "        y_rotat.append(y)\n",
    "        \n",
    "        x,y = vertical_flip(x_train[idx], y_train[idx])\n",
    "        x_vert.append(x)\n",
    "        y_vert.append(y)\n",
    "        \n",
    "        x,y = horizontal_flip(x_train[idx], y_train[idx])\n",
    "        x_flip.append(x)\n",
    "        y_flip.append(y)\n",
    "        \n",
    "        return np.array(x_rotat), np.array(y_rotat), np.array(x_flip), np.array(y_flip), np.array(x_vert), np.array(y_vert)\n",
    "\n",
    "def img_augmentation(x_test, y_test):\n",
    "   \n",
    "    x_rotat = []\n",
    "    y_rotat = []\n",
    "    x_flip = []\n",
    "    y_flip = []\n",
    "    x_nois = []\n",
    "    x_vert = []\n",
    "    y_vert = []\n",
    "    #x_rotat = []\n",
    "    #y_rotat =[]\n",
    "    for idx in range(len(x_test)):\n",
    "        x,y = random_rotation(x_test[idx], y_test[idx])\n",
    "        x_rotat.append(x)\n",
    "        y_rotat.append(y)\n",
    "        \n",
    "        x,y = vertical_flip(x_test[idx], y_test[idx])\n",
    "        x_vert.append(x)\n",
    "        y_vert.append(y)\n",
    "        \n",
    "        x,y = horizontal_flip(x_test[idx], y_test[idx])\n",
    "        x_flip.append(x)\n",
    "        y_flip.append(y)\n",
    "\n",
    "    return np.array(x_rotat), np.array(y_rotat), np.array(x_flip), np.array(y_flip), np.array(x_vert), np.array(y_vert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rotated, y_rotated, x_flipped, y_flipped, x_vertical, y_vertical = img_augmentation(x_train, y_train)\n",
    "x_rotated_t, y_rotated_t, x_flipped_t, y_flipped_t, x_vertical_t, y_vertical_t = img_augmentation(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para el conjunto de entrenamiento\n",
    "x_train_full = np.concatenate([x_train, x_rotated, x_flipped])\n",
    "y_train_full = np.concatenate([y_train, y_rotated, y_flipped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size = 0.20, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tamaño del conjunto de entrenamiento  : {}\".format(len(x_train)))\n",
    "print(\"Tamaño del conjunto de prueba       : {}\".format(len(x_test)))\n",
    "print(\"Tamaño del conjunto de validacion : {}\".format(len(x_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn_net(epochs_num,savename):\n",
    "\n",
    "    # Convolution Layers (BatchNorm after non-linear activation)\n",
    "\n",
    "    img_input = Input(shape= (192, 256, 3))\n",
    "    x = Conv2D(16, (5, 5), padding='same', name='conv1',strides= (1,1))(img_input)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(32, (3, 3), padding='same', name='conv2')(x)\n",
    "    x = BatchNormalization(name='bn2')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(64, (4, 4), padding='same', name='conv3')(x)\n",
    "    x = BatchNormalization(name='bn3')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(64, (4, 4), padding='same', name='conv4')(x)\n",
    "    x = BatchNormalization(name='bn4')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    \n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Conv2D(512, (3, 3), padding='same', name='conv5')(x)\n",
    "    x = BatchNormalization(name='bn5')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dense(1024, activation = 'relu', name='fc1')(x)\n",
    "    x = Dense(1024, activation = 'relu', name='fc2')(x)\n",
    "\n",
    "    # Deconvolution Layers (BatchNorm after non-linear activation)\n",
    "\n",
    "    x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv1')(x)\n",
    "    x = BatchNormalization(name='bn6')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv2')(x)\n",
    "    x = BatchNormalization(name='bn7')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(128, (3, 3), padding='same', name='deconv3')(x)\n",
    "    x = BatchNormalization(name='bn8')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2DTranspose(1, (3, 3), padding='same', name='deconv4')(x)\n",
    "    x = BatchNormalization(name='bn9')(x)\n",
    "    \n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Activation('sigmoid')(x)\n",
    "    pred = Reshape((192,256))(x)\n",
    "    \n",
    "    model = Model(inputs=img_input, outputs=pred)\n",
    "    \n",
    "    model.compile(optimizer= Adam(lr = 0.003), loss= [jaccard_distance]\n",
    "                  , metrics=[iou, dice_coef, precision, recall, accuracy])\n",
    "\n",
    "    hist = model.fit(x_train, y_train, epochs= epochs_num, batch_size= 18, validation_data= (x_val, y_val), verbose=1)\n",
    "\n",
    "    model.save(savename)\n",
    "    return model,hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "model, hist = fcn_net(epochs_num= 1, savename= 'fcn_1_epochs.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = Input(shape= (192, 256, 3))\n",
    "x = Conv2D(16, (5, 5), padding='same', name='conv1',strides= (1,1))(img_input)\n",
    "x = BatchNormalization(name='bn1')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(32, (3, 3), padding='same', name='conv2')(x)\n",
    "x = BatchNormalization(name='bn2')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, (4, 4), padding='same', name='conv3')(x)\n",
    "x = BatchNormalization(name='bn3')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (4, 4), padding='same', name='conv4')(x)\n",
    "x = BatchNormalization(name='bn4')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Conv2D(512, (3, 3), padding='same', name='conv5')(x)\n",
    "x = BatchNormalization(name='bn5')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(1024, activation = 'relu', name='fc1')(x)\n",
    "x = Dense(1024, activation = 'relu', name='fc2')(x)\n",
    "\n",
    "# Deconvolution Layers (BatchNorm after non-linear activation)\n",
    "\n",
    "x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv1')(x)\n",
    "x = BatchNormalization(name='bn6')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = UpSampling2D()(x)\n",
    "x = Conv2DTranspose(256, (3, 3), padding='same', name='deconv2')(x)\n",
    "x = BatchNormalization(name='bn7')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2DTranspose(128, (3, 3), padding='same', name='deconv3')(x)\n",
    "x = BatchNormalization(name='bn8')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = UpSampling2D()(x)\n",
    "x = Conv2DTranspose(1, (3, 3), padding='same', name='deconv4')(x)\n",
    "x = BatchNormalization(name='bn9')(x)\n",
    "\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Activation('sigmoid')(x)\n",
    "pred = Reshape((192,256))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = Model(inputs=img_input, outputs=pred)\n",
    "model_0.compile(optimizer= Adam(lr = 0.003), loss= ['binary_crossentropy'], metrics=[iou, dice_coef, precision, recall, accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.load_weights('fcn_1_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, hist = fcn_net(epochs_num= 120, savename= 'fcn_120_epoch.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carga el modelo y ademas carga el optimizador Adam, la función de costo y las métricas de evaluación\n",
    "model_1 = Model(inputs=img_input, outputs=pred)\n",
    "model_1.compile(optimizer= Adam(lr = 0.003), loss= ['binary_crossentropy'], metrics=[iou, dice_coef, precision, recall, accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carga los pesos entrenados previamente con 120 épocas\n",
    "model_1.load_weights('fcn_120_epoch.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n Estadisticas con 120 epocas sonre el conjunto de entrenamiento')\n",
    "print('\\n-------------Sobre el conjunto de entrenamiento--------------------------\\n')\n",
    "res = model_1.evaluate(x_train, y_train, batch_size= 18)\n",
    "print('--------------------------')\n",
    "print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n",
    "print('Coef. Dice: |   {:.2f}  |'.format(res[2]*100))\n",
    "print('Precision: |   {:.2f}  |'.format(res[3]*100))\n",
    "print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n",
    "print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n",
    "print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n",
    "print('--------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n -> Sobre el conjunto de prueba <-\\n')\n",
    "res = model_1.evaluate(x_test.astype('float32'), y_test.astype('float32'), batch_size= 18)\n",
    "print('-------------------------')\n",
    "print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n",
    "print('Coef. Dice: |   {:.2f}  |'.format(res[2]*100))\n",
    "print('Precision: |   {:.2f}  |'.format(res[3]*100))\n",
    "print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n",
    "print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n",
    "print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n",
    "print('--------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n -> Sobre el conjunto de validacion <- \\n')\n",
    "res = model_1.evaluate(x_val, y_val, batch_size= 18)\n",
    "print('------------------------')\n",
    "print('IOU:       |   {:.2f}  |'.format(res[1]*100))\n",
    "print('Dice Coef: |   {:.2f}  |'.format(res[2]*100))\n",
    "print('Precision: |   {:.2f}  |'.format(res[3]*100))\n",
    "print('Recall:    |   {:.2f}  |'.format(res[4]*100))\n",
    "print('Accuracy:  |   {:.2f}  |'.format(res[5]*100))\n",
    "print(\"Loss:      |   {:.2f}  |\".format(res[0]*100))\n",
    "print('-------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "#plt.suptitle('Estadistica de entrenamiento en el conjunto de entrenamiento', fontsize = 30, color='blue')\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(hist.history['loss'], 'red')\n",
    "plt.title('Curva de función de costo',fontsize = 18, color='black')\n",
    "plt.xlabel(\"Número de épocas \",fontsize = 18, color='black')\n",
    "plt.ylabel(\"Pérdida \",fontsize = 18, color='black')\n",
    "#plt.subplot(2,3,2)\n",
    "#plt.plot(hist.history['iou'], 'blue')\n",
    "#plt.title('Jaccard Index',fontsize = 18, color='black')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(hist.history['accuracy'], 'green')\n",
    "plt.title('Curva de Exactitud',fontsize = 18, color='black')\n",
    "plt.xlabel(\"Número de épocas \",fontsize = 18, color='black')\n",
    "plt.ylabel(\"Pérdida \",fontsize = 18, color='black')\n",
    "plt.show()\n",
    "#plt.savefig('unet_train_1.png',dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,16))\n",
    "\n",
    "plt.suptitle('Visualización de manglares predichas', fontsize = 18, color='black')\n",
    "\n",
    "img_pred = model_1.predict(x_test[49].reshape(1,192,256,3))\n",
    "plt.subplot(2,3,1)\n",
    "plt.imshow(x_test[49])\n",
    "plt.title('Imagen original')\n",
    "plt.subplot(2,3,2)\n",
    "plt.imshow(y_test[49], plt.cm.binary_r)\n",
    "plt.title('Máscara etiquetada')\n",
    "plt.subplot(2,3,3)\n",
    "plt.imshow(img_pred.reshape(192, 256), plt.cm.binary_r)\n",
    "plt.title('Máscara predicha')\n",
    "\n",
    "img_pred = model_1.predict(x_test[21].reshape(1,192,256,3))\n",
    "plt.subplot(2,3,4)\n",
    "plt.imshow(x_test[21])\n",
    "plt.title('Imagen original')\n",
    "plt.subplot(2,3,5)\n",
    "plt.imshow(y_test[21], plt.cm.binary_r)\n",
    "plt.title('Máscara etiquetada')\n",
    "plt.subplot(2,3,6)\n",
    "plt.imshow(img_pred.reshape(192, 256), plt.cm.binary_r)\n",
    "plt.title('Máscara predicha')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance(img):\n",
    "    sub = (model_1.predict(img.reshape(1,192,256,3))).flatten()\n",
    "\n",
    "    for i in range(len(sub)):\n",
    "        if sub[i] > 0.5:\n",
    "            sub[i] = 1\n",
    "        else:\n",
    "            sub[i] = 0\n",
    "    return sub\n",
    "plt.figure(figsize=(24,16))\n",
    "\n",
    "#plt.suptitle('Comparacion despues de la mejora', fontsize = 30, color='blue')\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "plt.imshow(x_test[21])\n",
    "plt.title('Imagen original')\n",
    "plt.subplot(2,3,2)\n",
    "plt.imshow(y_test[21],plt.cm.binary_r)\n",
    "plt.title('Máscara')\n",
    "plt.subplot(2,3,3)\n",
    "plt.imshow(enhance(x_test[21]).reshape(192,256), plt.cm.binary_r)\n",
    "plt.title('Predicción')\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "plt.imshow(x_test[19])\n",
    "plt.title('Imagen Original')\n",
    "plt.subplot(2,3,5)\n",
    "plt.imshow(y_test[19],plt.cm.binary_r)\n",
    "plt.title('Máscara')\n",
    "plt.subplot(2,3,6)\n",
    "plt.imshow(enhance(x_test[19]).reshape(192,256), plt.cm.binary_r)\n",
    "plt.title('Predicción')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
